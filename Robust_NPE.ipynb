{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import zuko\n",
    "import lampe.inference, lampe.utils\n",
    "from itertools import islice\n",
    "import flowjax\n",
    "from flowjax.flows import BlockNeuralAutoregressiveFlow, CouplingFlow\n",
    "from flowjax.train_utils import train_flow\n",
    "import jax.random as random\n",
    "import flowjax.distributions, flowjax.flows\n",
    "import jax\n",
    "from numpyro.distributions import (\n",
    "    Distribution,\n",
    "    Normal,\n",
    "    Bernoulli,\n",
    "    Cauchy,\n",
    "    constraints,\n",
    ")\n",
    "from flowjax.distributions import Distribution as FlowJaxDist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50000\n",
    "prior_over_mu = zuko.distributions.Normal(torch.Tensor([0.0]), torch.Tensor([25.0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_data_generating_process():\n",
    "    \"\"\"Computes x = (mean,var) of a sample of size 100 drawn from N(mu, 2) and mu drawn from a prior\n",
    "\n",
    "    Returns:\n",
    "        tuple: x, mu\n",
    "    \"\"\"\n",
    "    mu = torch.distributions.Normal(torch.Tensor([0]), torch.Tensor([1])).sample((1, )).detach().item()\n",
    "    dist = torch.distributions.Normal(mu, 2.0)\n",
    "    sample = dist.sample((100, ))\n",
    "    mean, var = torch.mean(sample).item(), torch.var(sample).item()\n",
    "    x = mean, var\n",
    "    return x, mu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation (line 1 & 2 of Algorithm 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator(thetas: torch.Tensor):\n",
    "    \"\"\"Simulator, maps theta -> x = (mean, var)\n",
    "\n",
    "    Args:\n",
    "        thetas (torch.Tensor): Parameters\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of size (theta.size, 2) of (mean, var)\n",
    "    \"\"\"\n",
    "    N = thetas.size()[0]\n",
    "    x = torch.empty((N, 2))\n",
    "    for i, theta in enumerate(thetas):\n",
    "        dist = torch.distributions.Normal(theta, 1.0)\n",
    "        samples = dist.sample((100,))\n",
    "        means, var = torch.mean(samples), torch.var(samples)\n",
    "        x[i][0], x[i][1] = means, var\n",
    "    return x\n",
    "\n",
    "def scale(quantity):\n",
    "    '''\n",
    "    Standardizes the quantity\n",
    "    '''\n",
    "    means, std = quantity.mean(axis=0), quantity.std(axis=0)\n",
    "    quantity = quantity - means\n",
    "    quantity = quantity/std\n",
    "    return quantity\n",
    "\n",
    "\n",
    "#Raw simulations\n",
    "theta_raw = prior_over_mu.sample((N, ))\n",
    "x_raw = simulator(theta_raw)\n",
    "#Standardized versions\n",
    "theta = scale(theta_raw)\n",
    "x = scale(x_raw)\n",
    "dataset = lampe.data.JointDataset(theta, x)\n",
    "\n",
    "\n",
    "#True observations \n",
    "y_raw = torch.tensor([ true_data_generating_process()[0] for j in range(N//10) ])\n",
    "y = scale(y_raw)\n",
    "\n",
    "theta_test = scale(prior_over_mu.sample((N//10, )))\n",
    "x_test = scale(simulator(theta_test))\n",
    "dataset_test = lampe.data.JointDataset(theta_test, x_test)\n",
    "\n",
    "'''Creates a 'true' dataset (theta*, x*) ~ p(theta, x)'''\n",
    "y_star_list = []\n",
    "theta_star_list = []\n",
    "for i in range(N//10):\n",
    "    y_star, theta_star = true_data_generating_process()\n",
    "    y_star_list.append(y_star)\n",
    "    theta_star_list.append(theta_star)\n",
    "y_star_raw = torch.tensor(y_star_list)\n",
    "theta_star_raw = torch.tensor(theta_star_list)\n",
    "theta_star = scale(theta_star_raw)\n",
    "y_star = scale(y_star_raw)\n",
    "dataset_star = lampe.data.JointDataset(theta_star.unsqueeze(1), y_star)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train NPE q(theta|x) on the simulated dataset {(thetai, xi)}, i=1, ... N\n",
    "Uses a neural spline flow defining the transform on the interval [-5, 5] using 10  spline segments and 5 coupling layers. The base of the flow is a standard Gaussian distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nsf(features, context):\n",
    "    \"\"\"Callable to isntanciate the NPE with NSFs\"\"\"\n",
    "    return zuko.flows.NSF(features, context, bins=10, transforms=5)\n",
    "q_NPE = lampe.inference.NPE(theta_dim = 1, x_dim=2, build=build_nsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 \n",
      " Epoch 1 \n",
      " Epoch 2 \n",
      " Epoch 3 \n",
      " Epoch 4 \n",
      " Epoch 5 \n",
      "Early stop at epoch 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NPE(\n",
       "  (flow): NSF(\n",
       "    (transforms): ModuleList(\n",
       "      (0-4): 5 x MaskedAutoregressiveTransform(\n",
       "        (base): MonotonicRQSTransform(bins=10)\n",
       "        (order): [0]\n",
       "        (hyper): MaskedMLP(\n",
       "          (0): MaskedLinear(in_features=3, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): MaskedLinear(in_features=64, out_features=64, bias=True)\n",
       "          (3): ReLU()\n",
       "          (4): MaskedLinear(in_features=64, out_features=29, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (base): DiagNormal(loc: tensor([0.]), scale: tensor([1.]))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Param for training\n",
    "max_epochs = 50\n",
    "learning_rate_NSF = 5*10e-4\n",
    "batch_size = 256\n",
    "#Optim\n",
    "optimizer = torch.optim.Adam(q_NPE.parameters(), learning_rate_NSF)\n",
    "step = lampe.utils.GDStep(optimizer)\n",
    "#Creates the loader\n",
    "loader = lampe.data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "loss = lampe.inference.NPELoss(q_NPE)\n",
    "\n",
    "#For early stopping \n",
    "with torch.no_grad():\n",
    "    min_loss = loss(theta_test, x_test)\n",
    "time_to_min=1\n",
    "min_loss_list = [min_loss]\n",
    "patience = 5 \n",
    "\n",
    "q_NPE.train()\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    loss_epoch = 0\n",
    "    for theta, x_batch in loader:\n",
    "        losses = loss(theta, x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += losses\n",
    "    print(f\" Epoch {epoch} \")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_test = loss(theta_test, x_test)\n",
    "        min_loss_list.append(loss_test)\n",
    "        \n",
    "        if len(min_loss_list) - np.argmin(min_loss_list) > patience:\n",
    "            print(f\"Early stop at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "q_NPE.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling theta here as in the 'classic' NPE framework (i.e. assuming no error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_NPE = q_NPE.sample(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train q(x) on {xi} i=1, ... N (so first gen the x)\n",
    "For q(x) uses of a block neural autoregressive flow, single hidden layer of size 8D, x in R^d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0\n",
      "Epoch = 1\n",
      "Epoch = 2\n",
      "Epoch = 3\n",
      "Epoch = 4\n",
      "Epoch = 5\n",
      "Epoch = 6\n",
      "Epoch = 7\n",
      "Epoch = 8\n",
      "Early stop at epoch 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 256\n",
    "max_epochs = 50\n",
    "learning_rate_BNAF = 1e-2\n",
    "epsilon = 1e-5\n",
    "q_x_NF = zuko.flows.NAF(features = 2, context=0, hidden_features=[8]*2,transforms=1)\n",
    "loader_x = torch.utils.data.DataLoader(x, batch_size=batch_size)\n",
    "\n",
    "optimizer = torch.optim.Adam(q_x_NF.parameters(), 1e-2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    min_loss = -q_x_NF().log_prob(x_test).mean()\n",
    "min_loss_list = [min_loss]\n",
    "for epoch in range(max_epochs):\n",
    "    loss_epoch = 0\n",
    "    print(f\"Epoch = {epoch}\")\n",
    "    for x_batch in loader_x:\n",
    "        loss =-q_x_NF().log_prob(x_batch).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        loss_test = -q_x_NF().log_prob(x_test).mean()\n",
    "        min_loss_list.append(loss_test)\n",
    "        if len(min_loss_list) - np.argmin(min_loss_list) > patience:\n",
    "            print(f\"Early stop at epoch {epoch}\")\n",
    "            break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample x~m from p(x | y0) % p(y0 \\ x) q(x), m = 1, ... M using MCMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spike and slab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100000\n",
    "warm_up_steps = 20000\n",
    "traj_length = 1\n",
    "target_acceptance_prob = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_slab(y):\n",
    "    rho = 1/2\n",
    "    sigma = 0.01\n",
    "    tau = 0.25\n",
    "    x = q_x_NF().sample()\n",
    "    z = torch.distributions.Bernoulli(rho).sample(y.shape)\n",
    "    normal = torch.distributions.Normal(x,sigma)\n",
    "    cauchy = torch.distributions.Cauchy(x, tau)\n",
    "    mask = torch.zeros_like(z)\n",
    "    mask[z==1] = 1\n",
    "    mask[z==0] = 0\n",
    "    sampled_values = torch.where(mask==1, cauchy.sample(z.shape), normal.sample(z.shape))\n",
    "    return sampled_values.sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MHQTransition(lampe.inference.MetropolisHastings):\n",
    "    def q(self, x:torch.Tensor):\n",
    "        return q_x_NF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_y_given_x(x):\n",
    "    z = torch.distributions.Bernoulli(1/2).sample(x.shape)\n",
    "    res = 1\n",
    "    for j,x_j in enumerate(x):\n",
    "        zj=z[j]\n",
    "        if not zj:\n",
    "            dist=  torch.distributions.Normal(x_j, 0.01)\n",
    "        else:\n",
    "            dist = torch.distributions.Cauchy(x_j, 0.25)\n",
    "        res *= dist.log_prob(y).exp().sum()\n",
    "    return res\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53548it [22:23, 39.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sampler \u001b[39m=\u001b[39m MHQTransition(q_x_NF()\u001b[39m.\u001b[39msample(),f\u001b[39m=\u001b[39mp_y_given_x)\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m     xm_samples_ \u001b[39m=\u001b[39m [s \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(sampler(M\u001b[39m+\u001b[39mwarm_up_steps,burn\u001b[39m=\u001b[39mwarm_up_steps))]\n\u001b[1;32m      4\u001b[0m     xm_samples_ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(xm_samples_)\n",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m sampler \u001b[39m=\u001b[39m MHQTransition(q_x_NF()\u001b[39m.\u001b[39msample(),f\u001b[39m=\u001b[39mp_y_given_x)\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m     xm_samples_ \u001b[39m=\u001b[39m [s \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(sampler(M\u001b[39m+\u001b[39mwarm_up_steps,burn\u001b[39m=\u001b[39mwarm_up_steps))]\n\u001b[1;32m      4\u001b[0m     xm_samples_ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(xm_samples_)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/lampe/inference.py:764\u001b[0m, in \u001b[0;36mMetropolisHastings.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m log_f_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_f(x)\n\u001b[1;32m    762\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    763\u001b[0m     \u001b[39m# y ~ q(y | x)\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq(x)\u001b[39m.\u001b[39;49msample()\n\u001b[1;32m    766\u001b[0m     \u001b[39m# log f(y)\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     log_f_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_f(y)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/distribution.py:158\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mGenerates a sample_shape shaped sample or sample_shape shaped batch of\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39msamples if the distribution parameters are batched.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrsample(sample_shape)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/distributions.py:121\u001b[0m, in \u001b[0;36mNormalizingFlow.rsample\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase\u001b[39m.\u001b[39msample(shape)\n\u001b[0;32m--> 121\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform\u001b[39m.\u001b[39;49minv(z)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/transforms.py:152\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mComputes the transform `x => y`.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(x)\n\u001b[1;32m    153\u001b[0m x_old, y_old \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_x_y\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m x_old:\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/transforms.py:108\u001b[0m, in \u001b[0;36mComposedTransform._call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    107\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m--> 108\u001b[0m         x \u001b[39m=\u001b[39m t(x)\n\u001b[1;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/transforms.py:257\u001b[0m, in \u001b[0;36m_InverseTransform.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    256\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inv\u001b[39m.\u001b[39;49m_inv_call(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/transforms.py:165\u001b[0m, in \u001b[0;36mTransform._inv_call\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mInverts the transform `y => x`.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inverse(y)\n\u001b[1;32m    166\u001b[0m x_old, y_old \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_x_y\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m y_old:\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/transforms.py:717\u001b[0m, in \u001b[0;36mAutoregressiveTransform._inverse\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    715\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(y)\n\u001b[1;32m    716\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpasses):\n\u001b[0;32m--> 717\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmeta(x)\u001b[39m.\u001b[39;49minv(y)\n\u001b[1;32m    719\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/transforms.py:257\u001b[0m, in \u001b[0;36m_InverseTransform.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    256\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inv\u001b[39m.\u001b[39;49m_inv_call(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/transforms.py:165\u001b[0m, in \u001b[0;36mTransform._inv_call\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mInverts the transform `y => x`.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inverse(y)\n\u001b[1;32m    166\u001b[0m x_old, y_old \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_x_y\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m y_old:\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/transforms.py:484\u001b[0m, in \u001b[0;36mMonotonicTransform._inverse\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inverse\u001b[39m(\u001b[39mself\u001b[39m, y: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m bisection(\n\u001b[1;32m    485\u001b[0m         f\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf,\n\u001b[1;32m    486\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    487\u001b[0m         a\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfull_like(y, \u001b[39m-\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound),\n\u001b[1;32m    488\u001b[0m         b\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfull_like(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound),\n\u001b[1;32m    489\u001b[0m         n\u001b[39m=\u001b[39;49mmath\u001b[39m.\u001b[39;49mceil(math\u001b[39m.\u001b[39;49mlog2(\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound \u001b[39m/\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)),\n\u001b[1;32m    490\u001b[0m         phi\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mphi,\n\u001b[1;32m    491\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/utils.py:53\u001b[0m, in \u001b[0;36mbisection\u001b[0;34m(f, y, a, b, n, phi)\u001b[0m\n\u001b[1;32m     50\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(a)\u001b[39m.\u001b[39mto(y)\n\u001b[1;32m     51\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(b)\u001b[39m.\u001b[39mto(y)\n\u001b[0;32m---> 53\u001b[0m \u001b[39mreturn\u001b[39;00m Bisection\u001b[39m.\u001b[39;49mapply(f, y, a, b, n, \u001b[39m*\u001b[39;49mphi)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/utils.py:73\u001b[0m, in \u001b[0;36mBisection.forward\u001b[0;34m(ctx, f, y, a, b, n, *phi)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m     71\u001b[0m     c \u001b[39m=\u001b[39m (a \u001b[39m+\u001b[39m b) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m---> 73\u001b[0m     mask \u001b[39m=\u001b[39m f(c) \u001b[39m<\u001b[39m y\n\u001b[1;32m     75\u001b[0m     a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(mask, c, a)\n\u001b[1;32m     76\u001b[0m     b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(mask, b, c)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/flows.py:600\u001b[0m, in \u001b[0;36mNeuralAutoregressiveTransform.f\u001b[0;34m(self, signal, x)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(\u001b[39mself\u001b[39m, signal: Tensor, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(\n\u001b[1;32m    601\u001b[0m         torch\u001b[39m.\u001b[39;49mcat(broadcast(x[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m], signal, ignore\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    602\u001b[0m     )\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/nn.py:239\u001b[0m, in \u001b[0;36mTwoWayELU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 239\u001b[0m     x0, x1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mchunk(x, \u001b[39m2\u001b[39;49m, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat((\n\u001b[1;32m    242\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mforward(x0),\n\u001b[1;32m    243\u001b[0m         \u001b[39m-\u001b[39m\u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mforward(\u001b[39m-\u001b[39mx1),\n\u001b[1;32m    244\u001b[0m     ), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sampler = MHQTransition(q_x_NF().sample(),f=p_y_given_x)\n",
    "with torch.no_grad():\n",
    "    xm_samples_ = [s for s in tqdm.tqdm(sampler(M+warm_up_steps,burn=warm_up_steps))]\n",
    "    xm_samples_ = torch.stack(xm_samples_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sampler \u001b[39m=\u001b[39m lampe\u001b[39m.\u001b[39minference\u001b[39m.\u001b[39mMetropolisHastings(q_x_NF()\u001b[39m.\u001b[39msample(),f\u001b[39m=\u001b[39mspike_slab)\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m     xm_samples \u001b[39m=\u001b[39m [s \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m sampler(M\u001b[39m+\u001b[39mwarm_up_steps,burn\u001b[39m=\u001b[39mwarm_up_steps)]\n\u001b[1;32m      4\u001b[0m     xm_samples \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(xm_samples)\n\u001b[1;32m      5\u001b[0m     xm_samples\u001b[39m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m sampler \u001b[39m=\u001b[39m lampe\u001b[39m.\u001b[39minference\u001b[39m.\u001b[39mMetropolisHastings(q_x_NF()\u001b[39m.\u001b[39msample(),f\u001b[39m=\u001b[39mspike_slab)\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m     xm_samples \u001b[39m=\u001b[39m [s \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m sampler(M\u001b[39m+\u001b[39mwarm_up_steps,burn\u001b[39m=\u001b[39mwarm_up_steps)]\n\u001b[1;32m      4\u001b[0m     xm_samples \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(xm_samples)\n\u001b[1;32m      5\u001b[0m     xm_samples\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/lampe/inference.py:767\u001b[0m, in \u001b[0;36mMetropolisHastings.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq(x)\u001b[39m.\u001b[39msample()\n\u001b[1;32m    766\u001b[0m \u001b[39m# log f(y)\u001b[39;00m\n\u001b[0;32m--> 767\u001b[0m log_f_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_f(y)\n\u001b[1;32m    769\u001b[0m \u001b[39m#     f(y)   q(x | y)\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[39m# a = ---- * --------\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[39m#     f(x)   q(y | x)\u001b[39;00m\n\u001b[1;32m    772\u001b[0m log_a \u001b[39m=\u001b[39m log_f_y \u001b[39m-\u001b[39m log_f_x\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/lampe/inference.py:745\u001b[0m, in \u001b[0;36mMetropolisHastings.__init__.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_f \u001b[39m=\u001b[39m log_f\n\u001b[1;32m    744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: f(x)\u001b[39m.\u001b[39mlog()\n\u001b[1;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma \u001b[39m=\u001b[39m sigma\n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36mspike_slab\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      3\u001b[0m sigma \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m\n\u001b[1;32m      4\u001b[0m tau \u001b[39m=\u001b[39m \u001b[39m0.25\u001b[39m\n\u001b[0;32m----> 5\u001b[0m x \u001b[39m=\u001b[39m q_x_NF()\u001b[39m.\u001b[39;49msample()\n\u001b[1;32m      6\u001b[0m z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mBernoulli(rho)\u001b[39m.\u001b[39msample(y\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m normal \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mNormal(x,sigma)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/distribution.py:158\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mGenerates a sample_shape shaped sample or sample_shape shaped batch of\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39msamples if the distribution parameters are batched.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrsample(sample_shape)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/distributions.py:121\u001b[0m, in \u001b[0;36mNormalizingFlow.rsample\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase\u001b[39m.\u001b[39msample(shape)\n\u001b[0;32m--> 121\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform\u001b[39m.\u001b[39;49minv(z)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/transforms.py:152\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mComputes the transform `x => y`.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(x)\n\u001b[1;32m    153\u001b[0m x_old, y_old \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_x_y\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m x_old:\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/transforms.py:108\u001b[0m, in \u001b[0;36mComposedTransform._call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    107\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m--> 108\u001b[0m         x \u001b[39m=\u001b[39m t(x)\n\u001b[1;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/transforms.py:257\u001b[0m, in \u001b[0;36m_InverseTransform.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    256\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inv\u001b[39m.\u001b[39;49m_inv_call(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/transforms.py:165\u001b[0m, in \u001b[0;36mTransform._inv_call\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mInverts the transform `y => x`.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inverse(y)\n\u001b[1;32m    166\u001b[0m x_old, y_old \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_x_y\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m y_old:\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/transforms.py:717\u001b[0m, in \u001b[0;36mAutoregressiveTransform._inverse\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    715\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(y)\n\u001b[1;32m    716\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpasses):\n\u001b[0;32m--> 717\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmeta(x)\u001b[39m.\u001b[39;49minv(y)\n\u001b[1;32m    719\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/transforms.py:257\u001b[0m, in \u001b[0;36m_InverseTransform.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    256\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inv\u001b[39m.\u001b[39;49m_inv_call(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/distributions/transforms.py:165\u001b[0m, in \u001b[0;36mTransform._inv_call\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mInverts the transform `y => x`.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inverse(y)\n\u001b[1;32m    166\u001b[0m x_old, y_old \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_x_y\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m y_old:\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/transforms.py:484\u001b[0m, in \u001b[0;36mMonotonicTransform._inverse\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inverse\u001b[39m(\u001b[39mself\u001b[39m, y: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m bisection(\n\u001b[1;32m    485\u001b[0m         f\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf,\n\u001b[1;32m    486\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    487\u001b[0m         a\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfull_like(y, \u001b[39m-\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound),\n\u001b[1;32m    488\u001b[0m         b\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfull_like(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound),\n\u001b[1;32m    489\u001b[0m         n\u001b[39m=\u001b[39;49mmath\u001b[39m.\u001b[39;49mceil(math\u001b[39m.\u001b[39;49mlog2(\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound \u001b[39m/\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)),\n\u001b[1;32m    490\u001b[0m         phi\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mphi,\n\u001b[1;32m    491\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/utils.py:53\u001b[0m, in \u001b[0;36mbisection\u001b[0;34m(f, y, a, b, n, phi)\u001b[0m\n\u001b[1;32m     50\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(a)\u001b[39m.\u001b[39mto(y)\n\u001b[1;32m     51\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(b)\u001b[39m.\u001b[39mto(y)\n\u001b[0;32m---> 53\u001b[0m \u001b[39mreturn\u001b[39;00m Bisection\u001b[39m.\u001b[39;49mapply(f, y, a, b, n, \u001b[39m*\u001b[39;49mphi)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/utils.py:73\u001b[0m, in \u001b[0;36mBisection.forward\u001b[0;34m(ctx, f, y, a, b, n, *phi)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m     71\u001b[0m     c \u001b[39m=\u001b[39m (a \u001b[39m+\u001b[39m b) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m---> 73\u001b[0m     mask \u001b[39m=\u001b[39m f(c) \u001b[39m<\u001b[39m y\n\u001b[1;32m     75\u001b[0m     a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(mask, c, a)\n\u001b[1;32m     76\u001b[0m     b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(mask, b, c)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/flows.py:600\u001b[0m, in \u001b[0;36mNeuralAutoregressiveTransform.f\u001b[0;34m(self, signal, x)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(\u001b[39mself\u001b[39m, signal: Tensor, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(\n\u001b[1;32m    601\u001b[0m         torch\u001b[39m.\u001b[39;49mcat(broadcast(x[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m], signal, ignore\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    602\u001b[0m     )\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/zuko/nn.py:239\u001b[0m, in \u001b[0;36mTwoWayELU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 239\u001b[0m     x0, x1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mchunk(x, \u001b[39m2\u001b[39;49m, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat((\n\u001b[1;32m    242\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mforward(x0),\n\u001b[1;32m    243\u001b[0m         \u001b[39m-\u001b[39m\u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mforward(\u001b[39m-\u001b[39mx1),\n\u001b[1;32m    244\u001b[0m     ), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sampler = lampe.inference.MetropolisHastings(q_x_NF().sample(),f=spike_slab)\n",
    "with torch.no_grad():\n",
    "    xm_samples = [s for s in sampler(M+warm_up_steps,burn=warm_up_steps)]\n",
    "    xm_samples = torch.stack(xm_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8244139 ,  0.01038768],\n",
       "       [-0.59854394, -0.6725981 ],\n",
       "       [-1.0299511 , -0.4994842 ],\n",
       "       ...,\n",
       "       [ 0.8339483 , -0.62175727],\n",
       "       [ 0.35281512, -0.27730352],\n",
       "       [ 0.39325714, -0.8362903 ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xm_samples_arr = xm_samples.detach().numpy()\n",
    "xm_samples_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1 = np.load(\"/home/tux/rnpe/denoise_xm_paper.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = xm_samples_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547636363636364"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "#class0 = np.load(\"/home/tux/rnpe/mycode/xmMCMCLampe.npy\")\n",
    "#class0 = x_samples\n",
    "#class1 = np.load(\"/home/tux/rnpe/denoise_xm_paper.npy\",allow_pickle=True)\n",
    "#class0 = q_x_NF.forward().sample(class1.shape).detach().numpy()\n",
    "class0_labels = np.zeros(len(class0))\n",
    "class1_labels = np.ones(class1.shape[0])\n",
    "data = np.concatenate((class0,class1), axis=0)\n",
    "labels = np.concatenate((class0_labels, class1_labels), axis=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,labels)\n",
    "\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = sklearn.metrics.accuracy_score(y_test,y_pred)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample theta ~q(theta | xm), m = 1, ..., M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    thetasm = q_NPE.sample(xm_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_coverage(q_NPE, theta_star, y_star, alpha):\n",
    "    cov = 0\n",
    "    for i in range(len(theta_star)):\n",
    "        q = q_NPE(theta_star[i], y_star[i])\n",
    "        cr = np.percentile(q.detach().numpy(), [100*alpha/2, 100*(1-alpha/2)])\n",
    "        if theta_star[i] >= cr[0] and theta_star[i] <= cr[1]:\n",
    "            cov +=1\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xm_samples_ = xm_samples[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = lampe.data.JointDataset(theta_star.unsqueeze_(1),xm_samples_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:25<00:00, 34.31pair/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lampe.diagnostics import expected_coverage_mc, expected_coverage_ni\n",
    "npe_levels, npe_coverages = expected_coverage_mc(q_NPE.flow, dataset_star)#TODO essayer ici de changer params\n",
    "from lampe.plots import nice_rc, coverage_plot\n",
    "fig = coverage_plot(npe_levels, npe_coverages, legend='NPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?pair/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[192], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#TODO Plot le NPE aussi mais il faut faire prendre les xm ?\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlampe\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdiagnostics\u001b[39;00m \u001b[39mimport\u001b[39;00m expected_coverage_mc, expected_coverage_ni\n\u001b[0;32m----> 4\u001b[0m npe_levels, npe_coverages \u001b[39m=\u001b[39m expected_coverage_mc(q_NPE, test)\u001b[39m#TODO essayer ici de changer params\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlampe\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplots\u001b[39;00m \u001b[39mimport\u001b[39;00m nice_rc, coverage_plot\n\u001b[1;32m      6\u001b[0m fig \u001b[39m=\u001b[39m coverage_plot(npe_levels, npe_coverages, legend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNPE\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/lampe/diagnostics.py:62\u001b[0m, in \u001b[0;36mexpected_coverage_mc\u001b[0;34m(posterior, pairs, n)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m theta, x \u001b[39min\u001b[39;00m tqdm(pairs, unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpair\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 62\u001b[0m         dist \u001b[39m=\u001b[39m posterior(x)\n\u001b[1;32m     64\u001b[0m         samples \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39msample((n,))\n\u001b[1;32m     65\u001b[0m         mask \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mlog_prob(theta) \u001b[39m<\u001b[39m dist\u001b[39m.\u001b[39mlog_prob(samples)\n",
      "File \u001b[0;32m~/miniconda3/envs/rnpe_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "#TODO Plot le NPE aussi mais il faut faire prendre les xm ?\n",
    "\n",
    "from lampe.diagnostics import expected_coverage_mc, expected_coverage_ni\n",
    "npe_levels, npe_coverages = expected_coverage_mc(q_NPE, test)#TODO essayer ici de changer params\n",
    "from lampe.plots import nice_rc, coverage_plot\n",
    "fig = coverage_plot(npe_levels, npe_coverages, legend='NPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([-0.85242  ,  0.5124575], dtype=float32),\n",
       " Array(-0.03808814, dtype=float32))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_x.bijection.inverse_and_log_abs_det_jacobian(x_jax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_prob(flow, thetas, x):\n",
    "    res = []\n",
    "    for i, theta in enumerate(thetas.unsqueeze_(1)):\n",
    "        xi = x[i]\n",
    "        log_prob = flow.flow(xi).log_prob(theta) \n",
    "        res.append(log_prob.detach().item())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs_RNPE = compute_log_prob(q_NPE, theta_star, xm_samples)\n",
    "log_probs_NPE = compute_log_prob(q_NPE, theta_star, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7fe1d77dcaf0>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe1d77dcd90>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe1d77ebdc0>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe1d78210a0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7fe1d77eb070>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe1d77eb310>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe1d7821340>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe1d78215e0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7fe1d77dc850>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe1d77ebb20>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7fe1d77eb5b0>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe1d7821880>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7fe1d77eb850>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe1d7821b20>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([log_probs_NPE, log_probs_RNPE])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut aussi faire les 2 autres simu cad NPE (comme avant) et en mettant directement le modele d'erreur dans le simu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_simulator():\n",
    "    #Sample the parameters theta [mu]\n",
    "    sigma = 0.01\n",
    "    tau = 0.25\n",
    "    rho = 1/2\n",
    "    x_noisy_raw, theta_noisy_raw = x_raw, theta_raw\n",
    "    x_noisy_test, theta_noisy_test = x_test, theta_test\n",
    "\n",
    "    for i, x in enumerate(x_noisy_raw):\n",
    "        spike_dist = torch.distributions.Normal(x, torch.Tensor([sigma]))\n",
    "        slab_dist = torch.distributions.Cauchy(x, torch.Tensor([tau]))\n",
    "        spike = ((1 - rho) *spike_dist.sample((1, )))[0]\n",
    "        slab = (rho * slab_dist.sample((1, )))[0]\n",
    "        x_noisy_raw[i] += spike + slab\n",
    "    for i, x in enumerate(x_noisy_test):\n",
    "        spike_dist = torch.distributions.Normal(x, torch.Tensor([sigma]))\n",
    "        slab_dist = torch.distributions.Cauchy(x, torch.Tensor([tau]))\n",
    "        spike = ((1 - rho) *spike_dist.sample((1, )))[0]\n",
    "        slab = (rho * slab_dist.sample((1, )))[0]\n",
    "        x_noisy_test += spike + slab\n",
    "    x_noisy = scale(x_noisy_test)\n",
    "    theta_noisy = scale(theta_noisy_raw)\n",
    "    return x_noisy, theta_noisy, x_noisy_test, theta_noisy_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisy, thetas, X_noisy_test, thetas_test = noisy_simulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_NPE_noisy = zuko.flows.NSF(features=1, context=2, bins=10, transforms=5) #TODO! Continuer ICI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnpe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
