{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Problem description**\n",
    "\n",
    "Simple model $x = \\theta + \\epsilon \\ \\text{with}\\ \\epsilon\\sim \\mathcal{N}(0 ; \\sigma^{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1 #sigma²=0.01\n",
    "mu0 = 3\n",
    "sigma0 = 2\n",
    "\n",
    "sigma_T = torch.Tensor([sigma])\n",
    "mu0_T = torch.Tensor([mu0])\n",
    "sigma0_T = torch.Tensor([sigma0])\n",
    "\n",
    "base_distribution = torch.distributions.Normal(torch.Tensor([0.0]), torch.Tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(N):\n",
    "    res = torch.Tensor( N, 2)\n",
    "    thetas = torch.distributions.Normal(mu0_T, sigma0_T).sample((N, 1))\n",
    "    epsilons = torch.distributions.Normal(torch.Tensor([0]), sigma_T).sample((N, 1))\n",
    "    x = thetas + epsilons\n",
    "    res[:,0] = x.squeeze()\n",
    "    res[:,1] = thetas.squeeze()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7310, 2.7182],\n",
       "        [2.0699, 2.0615],\n",
       "        [2.5964, 2.4708],\n",
       "        ...,\n",
       "        [4.2726, 4.4063],\n",
       "        [0.0995, 0.2185],\n",
       "        [1.3500, 1.3047]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = generate_dataset(1000)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flow(nn.Module):\n",
    "    \n",
    "    def __init__(self,omega, beta, gamma, base):#TODO init auto si alpha, beta, gamma pas précisé\n",
    "        \n",
    "        super(flow, self).__init__()\n",
    "        self.omega = nn.Parameter(torch.Tensor([omega]), requires_grad=True)\n",
    "        self.beta = nn.Parameter(torch.Tensor([beta]), requires_grad= True)\n",
    "        self.gamma = nn.Parameter(torch.Tensor([gamma]), requires_grad= True)\n",
    "        self.base = base\n",
    "        \n",
    "    def forward(self,z, x):\n",
    "        theta = torch.exp(self.omega)*z + (self.beta * x + self.gamma)\n",
    "        return theta\n",
    "    \n",
    "    def loss(self, thetas, X):\n",
    "        res = 0\n",
    "        '''for i,x in enumerate(X):\n",
    "            est_mean = self.beta*x + self.gamma\n",
    "            est_var = torch.exp(self.omega)**2\n",
    "            logprob = torch.distributions.Normal(torch.Tensor(est_mean), torch.Tensor(est_var)).log_prob(thetas[i])\n",
    "            res += logprob\n",
    "        '''    \n",
    "        est_mean = self.beta*x + self.gamma\n",
    "        est_std = torch.exp(self.omega)\n",
    "        logprob = torch.distributions.Normal(torch.Tensor(est_mean), torch.Tensor(est_std)).log_prob(thetas)\n",
    "        res += logprob.sum()\n",
    "        return - res.mean()\n",
    "        \n",
    "\n",
    "f = flow(1.0, 1.0, 1.0, base_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 0 and loss = 1987.188720703125\n",
      "Iter = 20 and loss = 1959.2271728515625\n",
      "Iter = 40 and loss = 1931.7666015625\n",
      "Iter = 60 and loss = 1904.93310546875\n",
      "Iter = 80 and loss = 1878.802978515625\n",
      "Iter = 100 and loss = 1853.42236328125\n",
      "Iter = 120 and loss = 1828.8125\n",
      "Iter = 140 and loss = 1804.9681396484375\n",
      "Iter = 160 and loss = 1781.8583984375\n",
      "Iter = 180 and loss = 1759.4261474609375\n",
      "Iter = 200 and loss = 1737.5911865234375\n",
      "Iter = 220 and loss = 1716.2593994140625\n",
      "Iter = 240 and loss = 1695.32763671875\n",
      "Iter = 260 and loss = 1674.6966552734375\n",
      "Iter = 280 and loss = 1654.2767333984375\n",
      "Iter = 300 and loss = 1633.993408203125\n",
      "Iter = 320 and loss = 1613.7900390625\n",
      "Iter = 340 and loss = 1593.626220703125\n",
      "Iter = 360 and loss = 1573.474365234375\n",
      "Iter = 380 and loss = 1553.316650390625\n",
      "Iter = 400 and loss = 1533.14208984375\n",
      "Iter = 420 and loss = 1512.94189453125\n",
      "Iter = 440 and loss = 1492.71044921875\n",
      "Iter = 460 and loss = 1472.4429931640625\n",
      "Iter = 480 and loss = 1452.1358642578125\n",
      "Iter = 500 and loss = 1431.78564453125\n",
      "Iter = 520 and loss = 1411.3896484375\n",
      "Iter = 540 and loss = 1390.9459228515625\n",
      "Iter = 560 and loss = 1370.4532470703125\n",
      "Iter = 580 and loss = 1349.9107666015625\n",
      "Iter = 600 and loss = 1329.318115234375\n",
      "Iter = 620 and loss = 1308.6754150390625\n",
      "Iter = 640 and loss = 1287.984375\n",
      "Iter = 660 and loss = 1267.24560546875\n",
      "Iter = 680 and loss = 1246.4619140625\n",
      "Iter = 700 and loss = 1225.6358642578125\n",
      "Iter = 720 and loss = 1204.770263671875\n",
      "Iter = 740 and loss = 1183.8692626953125\n",
      "Iter = 760 and loss = 1162.936767578125\n",
      "Iter = 780 and loss = 1141.977783203125\n",
      "Iter = 800 and loss = 1120.997314453125\n",
      "Iter = 820 and loss = 1100.0006103515625\n",
      "Iter = 840 and loss = 1078.993896484375\n",
      "Iter = 860 and loss = 1057.9830322265625\n",
      "Iter = 880 and loss = 1036.9742431640625\n",
      "Iter = 900 and loss = 1015.9742431640625\n",
      "Iter = 920 and loss = 994.9893798828125\n",
      "Iter = 940 and loss = 974.0261840820312\n",
      "Iter = 960 and loss = 953.0910034179688\n",
      "Iter = 980 and loss = 932.1903076171875\n",
      "Iter = 1000 and loss = 911.32958984375\n",
      "Iter = 1020 and loss = 890.514404296875\n",
      "Iter = 1040 and loss = 869.7498168945312\n",
      "Iter = 1060 and loss = 849.0400390625\n",
      "Iter = 1080 and loss = 828.3890380859375\n",
      "Iter = 1100 and loss = 807.7998046875\n",
      "Iter = 1120 and loss = 787.2742919921875\n",
      "Iter = 1140 and loss = 766.8141479492188\n",
      "Iter = 1160 and loss = 746.420166015625\n",
      "Iter = 1180 and loss = 726.0924072265625\n",
      "Iter = 1200 and loss = 705.8300170898438\n",
      "Iter = 1220 and loss = 685.6319580078125\n",
      "Iter = 1240 and loss = 665.4962158203125\n",
      "Iter = 1260 and loss = 645.421142578125\n",
      "Iter = 1280 and loss = 625.4044189453125\n",
      "Iter = 1300 and loss = 605.4437255859375\n",
      "Iter = 1320 and loss = 585.536865234375\n",
      "Iter = 1340 and loss = 565.681884765625\n",
      "Iter = 1360 and loss = 545.876953125\n",
      "Iter = 1380 and loss = 526.1207885742188\n",
      "Iter = 1400 and loss = 506.4122314453125\n",
      "Iter = 1420 and loss = 486.7503356933594\n",
      "Iter = 1440 and loss = 467.1354064941406\n",
      "Iter = 1460 and loss = 447.5672912597656\n",
      "Iter = 1480 and loss = 428.04620361328125\n",
      "Iter = 1500 and loss = 408.5728759765625\n",
      "Iter = 1520 and loss = 389.14794921875\n",
      "Iter = 1540 and loss = 369.7724609375\n",
      "Iter = 1560 and loss = 350.4477233886719\n",
      "Iter = 1580 and loss = 331.1748352050781\n",
      "Iter = 1600 and loss = 311.9551086425781\n",
      "Iter = 1620 and loss = 292.7899169921875\n",
      "Iter = 1640 and loss = 273.680908203125\n",
      "Iter = 1660 and loss = 254.62960815429688\n",
      "Iter = 1680 and loss = 235.63754272460938\n",
      "Iter = 1700 and loss = 216.70672607421875\n",
      "Iter = 1720 and loss = 197.8386993408203\n",
      "Iter = 1740 and loss = 179.03549194335938\n",
      "Iter = 1760 and loss = 160.29922485351562\n",
      "Iter = 1780 and loss = 141.63174438476562\n",
      "Iter = 1800 and loss = 123.03514099121094\n",
      "Iter = 1820 and loss = 104.51178741455078\n",
      "Iter = 1840 and loss = 86.06388854980469\n",
      "Iter = 1860 and loss = 67.69381713867188\n",
      "Iter = 1880 and loss = 49.40423583984375\n",
      "Iter = 1900 and loss = 31.19746208190918\n",
      "Iter = 1920 and loss = 13.076515197753906\n",
      "Iter = 1940 and loss = -4.956194877624512\n",
      "Iter = 1960 and loss = -22.897741317749023\n",
      "Iter = 1980 and loss = -40.74529266357422\n",
      "Iter = 2000 and loss = -58.495689392089844\n",
      "Iter = 2020 and loss = -76.14588928222656\n",
      "Iter = 2040 and loss = -93.6927261352539\n",
      "Iter = 2060 and loss = -111.13306427001953\n",
      "Iter = 2080 and loss = -128.46270751953125\n",
      "Iter = 2100 and loss = -145.6788787841797\n",
      "Iter = 2120 and loss = -162.7777099609375\n",
      "Iter = 2140 and loss = -179.7557830810547\n",
      "Iter = 2160 and loss = -196.60922241210938\n",
      "Iter = 2180 and loss = -213.33401489257812\n",
      "Iter = 2200 and loss = -229.9264373779297\n",
      "Iter = 2220 and loss = -246.38246154785156\n",
      "Iter = 2240 and loss = -262.6976318359375\n",
      "Iter = 2260 and loss = -278.86798095703125\n",
      "Iter = 2280 and loss = -294.8891906738281\n",
      "Iter = 2300 and loss = -310.7569274902344\n",
      "Iter = 2320 and loss = -326.46673583984375\n",
      "Iter = 2340 and loss = -342.0140686035156\n",
      "Iter = 2360 and loss = -357.3943786621094\n",
      "Iter = 2380 and loss = -372.6031188964844\n",
      "Iter = 2400 and loss = -387.6357421875\n",
      "Iter = 2420 and loss = -402.48736572265625\n",
      "Iter = 2440 and loss = -417.1531982421875\n",
      "Iter = 2460 and loss = -431.6282043457031\n",
      "Iter = 2480 and loss = -445.9081726074219\n",
      "Iter = 2500 and loss = -459.98809814453125\n",
      "Iter = 2520 and loss = -473.86309814453125\n",
      "Iter = 2540 and loss = -487.5283203125\n",
      "Iter = 2560 and loss = -500.9791259765625\n",
      "Iter = 2580 and loss = -514.210693359375\n",
      "Iter = 2600 and loss = -527.218505859375\n",
      "Iter = 2620 and loss = -539.9976196289062\n",
      "Iter = 2640 and loss = -552.5440673828125\n",
      "Iter = 2660 and loss = -564.8528442382812\n",
      "Iter = 2680 and loss = -576.919921875\n",
      "Iter = 2700 and loss = -588.740966796875\n",
      "Iter = 2720 and loss = -600.3119506835938\n",
      "Iter = 2740 and loss = -611.629150390625\n",
      "Iter = 2760 and loss = -622.688720703125\n",
      "Iter = 2780 and loss = -633.4873657226562\n",
      "Iter = 2800 and loss = -644.0217895507812\n",
      "Iter = 2820 and loss = -654.28857421875\n",
      "Iter = 2840 and loss = -664.2852783203125\n",
      "Iter = 2860 and loss = -674.00927734375\n",
      "Iter = 2880 and loss = -683.4585571289062\n",
      "Iter = 2900 and loss = -692.631103515625\n",
      "Iter = 2920 and loss = -701.525390625\n",
      "Iter = 2940 and loss = -710.1400756835938\n",
      "Iter = 2960 and loss = -718.4746704101562\n",
      "Iter = 2980 and loss = -726.528564453125\n",
      "Iter = 3000 and loss = -734.3017578125\n",
      "Iter = 3020 and loss = -741.7945556640625\n",
      "Iter = 3040 and loss = -749.0077514648438\n",
      "Iter = 3060 and loss = -755.9425048828125\n",
      "Iter = 3080 and loss = -762.6005859375\n",
      "Iter = 3100 and loss = -768.9839477539062\n",
      "Iter = 3120 and loss = -775.0952758789062\n",
      "Iter = 3140 and loss = -780.9375\n",
      "Iter = 3160 and loss = -786.5142822265625\n",
      "Iter = 3180 and loss = -791.8291625976562\n",
      "Iter = 3200 and loss = -796.8862915039062\n",
      "Iter = 3220 and loss = -801.6909790039062\n",
      "Iter = 3240 and loss = -806.2476806640625\n",
      "Iter = 3260 and loss = -810.5620727539062\n",
      "Iter = 3280 and loss = -814.6403198242188\n",
      "Iter = 3300 and loss = -818.4882202148438\n",
      "Iter = 3320 and loss = -822.11279296875\n",
      "Iter = 3340 and loss = -825.520263671875\n",
      "Iter = 3360 and loss = -828.7178344726562\n",
      "Iter = 3380 and loss = -831.7130737304688\n",
      "Iter = 3400 and loss = -834.5132446289062\n",
      "Iter = 3420 and loss = -837.1260375976562\n",
      "Iter = 3440 and loss = -839.5567016601562\n",
      "Iter = 3460 and loss = -841.8131103515625\n",
      "Iter = 3480 and loss = -843.9174194335938\n",
      "Iter = 3500 and loss = -845.8589477539062\n",
      "Iter = 3520 and loss = -847.65234375\n",
      "Iter = 3540 and loss = -849.3054809570312\n",
      "Iter = 3560 and loss = -850.826171875\n",
      "Iter = 3580 and loss = -852.2221069335938\n",
      "Iter = 3600 and loss = -853.5008544921875\n",
      "Iter = 3620 and loss = -854.6696166992188\n",
      "Iter = 3640 and loss = -855.7355346679688\n",
      "Iter = 3660 and loss = -856.7057495117188\n",
      "Iter = 3680 and loss = -857.5867919921875\n",
      "Iter = 3700 and loss = -858.38525390625\n",
      "Iter = 3720 and loss = -859.107177734375\n",
      "Iter = 3740 and loss = -859.7584838867188\n",
      "Iter = 3760 and loss = -860.2957153320312\n",
      "Iter = 3780 and loss = -860.8646850585938\n",
      "Iter = 3800 and loss = -861.3426513671875\n",
      "Iter = 3820 and loss = -861.765625\n",
      "Iter = 3840 and loss = -862.142333984375\n",
      "Iter = 3860 and loss = -862.477783203125\n",
      "Iter = 3880 and loss = -862.7760009765625\n",
      "Iter = 3900 and loss = -863.0401611328125\n",
      "Iter = 3920 and loss = -863.2739868164062\n",
      "Iter = 3940 and loss = -863.4803466796875\n",
      "Iter = 3960 and loss = -863.6620483398438\n",
      "Iter = 3980 and loss = -863.8216552734375\n",
      "Iter = 4000 and loss = -863.961669921875\n",
      "Iter = 4020 and loss = -864.0841674804688\n",
      "Iter = 4040 and loss = -864.191162109375\n",
      "Iter = 4060 and loss = -864.2844848632812\n",
      "Iter = 4080 and loss = -864.3654174804688\n",
      "Iter = 4100 and loss = -864.435791015625\n",
      "Iter = 4120 and loss = -864.49658203125\n",
      "Iter = 4140 and loss = -864.5492553710938\n",
      "Iter = 4160 and loss = -864.5946044921875\n",
      "Iter = 4180 and loss = -864.598388671875\n",
      "Iter = 4200 and loss = -864.6668701171875\n",
      "Iter = 4220 and loss = -864.695556640625\n",
      "Iter = 4240 and loss = -864.719970703125\n",
      "Iter = 4260 and loss = -864.740966796875\n",
      "Iter = 4280 and loss = -864.7586669921875\n",
      "Iter = 4300 and loss = -864.7738647460938\n",
      "Iter = 4320 and loss = -864.78662109375\n",
      "Iter = 4340 and loss = -864.7973022460938\n",
      "Iter = 4360 and loss = -864.8064575195312\n",
      "Iter = 4380 and loss = -864.814208984375\n",
      "Iter = 4400 and loss = -864.820556640625\n",
      "Iter = 4420 and loss = -864.8259887695312\n",
      "Iter = 4440 and loss = -864.83056640625\n",
      "Iter = 4460 and loss = -864.8342895507812\n",
      "Iter = 4480 and loss = -864.8374633789062\n",
      "Iter = 4500 and loss = -864.8400268554688\n",
      "Iter = 4520 and loss = -864.8423461914062\n",
      "Iter = 4540 and loss = -864.843994140625\n",
      "Iter = 4560 and loss = -864.845458984375\n",
      "Iter = 4580 and loss = -864.8466796875\n",
      "Iter = 4600 and loss = -864.8477172851562\n",
      "Iter = 4620 and loss = -864.8485717773438\n",
      "Iter = 4640 and loss = -864.8411254882812\n",
      "Iter = 4660 and loss = -864.848388671875\n",
      "Iter = 4680 and loss = -864.8500366210938\n",
      "Iter = 4700 and loss = -864.8505859375\n",
      "Iter = 4720 and loss = -864.850830078125\n",
      "Iter = 4740 and loss = -864.85107421875\n",
      "Iter = 4760 and loss = -864.851318359375\n",
      "Iter = 4780 and loss = -864.8513793945312\n",
      "Iter = 4800 and loss = -864.8515625\n",
      "Iter = 4820 and loss = -864.847412109375\n",
      "Iter = 4840 and loss = -864.8517456054688\n",
      "Iter = 4860 and loss = -864.8516845703125\n",
      "Iter = 4880 and loss = -864.8516845703125\n",
      "Iter = 4900 and loss = -864.851806640625\n",
      "Iter = 4920 and loss = -864.851806640625\n",
      "Iter = 4940 and loss = -864.8519287109375\n",
      "Iter = 4960 and loss = -864.8518676757812\n",
      "Iter = 4980 and loss = -864.85205078125\n",
      "Iter = 5000 and loss = -864.8519287109375\n",
      "Iter = 5020 and loss = -864.8519897460938\n",
      "Iter = 5040 and loss = -864.8519897460938\n",
      "Iter = 5060 and loss = -864.8519897460938\n",
      "Iter = 5080 and loss = -864.8519897460938\n",
      "Iter = 5100 and loss = -864.8391723632812\n",
      "Iter = 5120 and loss = -864.8517456054688\n",
      "Iter = 5140 and loss = -864.851806640625\n",
      "Iter = 5160 and loss = -864.8519287109375\n",
      "Iter = 5180 and loss = -864.8519287109375\n",
      "Iter = 5200 and loss = -864.8519897460938\n",
      "Iter = 5220 and loss = -864.8519287109375\n",
      "Iter = 5240 and loss = -864.8519287109375\n",
      "Iter = 5260 and loss = -864.85205078125\n",
      "Iter = 5280 and loss = -864.8519897460938\n",
      "Iter = 5300 and loss = -864.8519897460938\n",
      "Iter = 5320 and loss = -864.84033203125\n",
      "Iter = 5340 and loss = -864.8519287109375\n",
      "Iter = 5360 and loss = -864.8519897460938\n",
      "Iter = 5380 and loss = -864.8519897460938\n",
      "Iter = 5400 and loss = -864.8519897460938\n",
      "Iter = 5420 and loss = -864.8519287109375\n",
      "Iter = 5440 and loss = -864.85205078125\n",
      "Iter = 5460 and loss = -864.8519287109375\n",
      "Iter = 5480 and loss = -864.8453369140625\n",
      "Iter = 5500 and loss = -864.850341796875\n",
      "Iter = 5520 and loss = -864.8519287109375\n",
      "Iter = 5540 and loss = -864.8519287109375\n",
      "Iter = 5560 and loss = -864.85205078125\n",
      "Iter = 5580 and loss = -864.85205078125\n",
      "Iter = 5600 and loss = -864.8519287109375\n",
      "Iter = 5620 and loss = -864.85205078125\n",
      "Iter = 5640 and loss = -864.8499755859375\n",
      "Iter = 5660 and loss = -864.848876953125\n",
      "Iter = 5680 and loss = -864.8515625\n",
      "Iter = 5700 and loss = -864.8519897460938\n",
      "Iter = 5720 and loss = -864.85205078125\n",
      "Iter = 5740 and loss = -864.8519897460938\n",
      "Iter = 5760 and loss = -864.8519897460938\n",
      "Iter = 5780 and loss = -864.8519897460938\n",
      "Iter = 5800 and loss = -864.85205078125\n",
      "Iter = 5820 and loss = -864.8519897460938\n",
      "Iter = 5840 and loss = -864.8509521484375\n",
      "Iter = 5860 and loss = -864.8497314453125\n",
      "Iter = 5880 and loss = -864.85205078125\n",
      "Iter = 5900 and loss = -864.8519897460938\n",
      "Iter = 5920 and loss = -864.8519287109375\n",
      "Iter = 5940 and loss = -864.85205078125\n",
      "Iter = 5960 and loss = -864.8519287109375\n",
      "Iter = 5980 and loss = -864.8466186523438\n",
      "Iter = 6000 and loss = -864.851806640625\n",
      "Iter = 6020 and loss = -864.8519287109375\n",
      "Iter = 6040 and loss = -864.8519897460938\n",
      "Iter = 6060 and loss = -864.8519287109375\n",
      "Iter = 6080 and loss = -864.8519287109375\n",
      "Iter = 6100 and loss = -864.846923828125\n",
      "Iter = 6120 and loss = -864.8518676757812\n",
      "Iter = 6140 and loss = -864.8519897460938\n",
      "Iter = 6160 and loss = -864.8519897460938\n",
      "Iter = 6180 and loss = -864.8521118164062\n",
      "Iter = 6200 and loss = -864.8519287109375\n",
      "Iter = 6220 and loss = -864.851806640625\n",
      "Iter = 6240 and loss = -864.8482055664062\n",
      "Iter = 6260 and loss = -864.8516235351562\n",
      "Iter = 6280 and loss = -864.8518676757812\n",
      "Iter = 6300 and loss = -864.8519897460938\n",
      "Iter = 6320 and loss = -864.85205078125\n",
      "Iter = 6340 and loss = -864.8519287109375\n",
      "Iter = 6360 and loss = -864.8518676757812\n",
      "Iter = 6380 and loss = -864.8475341796875\n",
      "Iter = 6400 and loss = -864.8510131835938\n",
      "Iter = 6420 and loss = -864.851806640625\n",
      "Iter = 6440 and loss = -864.8519897460938\n",
      "Iter = 6460 and loss = -864.85205078125\n",
      "Iter = 6480 and loss = -864.8519287109375\n",
      "Iter = 6500 and loss = -864.8521118164062\n",
      "Iter = 6520 and loss = -864.8519897460938\n",
      "Iter = 6540 and loss = -864.83642578125\n",
      "Iter = 6560 and loss = -864.8510131835938\n",
      "Iter = 6580 and loss = -864.851806640625\n",
      "Iter = 6600 and loss = -864.85205078125\n",
      "Iter = 6620 and loss = -864.8519287109375\n",
      "Iter = 6640 and loss = -864.85205078125\n",
      "Iter = 6660 and loss = -864.8519897460938\n",
      "Iter = 6680 and loss = -864.85205078125\n",
      "Iter = 6700 and loss = -864.8521118164062\n",
      "Iter = 6720 and loss = -864.85205078125\n",
      "Iter = 6740 and loss = -864.8363037109375\n",
      "Iter = 6760 and loss = -864.8506469726562\n",
      "Iter = 6780 and loss = -864.8517456054688\n",
      "Iter = 6800 and loss = -864.8519897460938\n",
      "Iter = 6820 and loss = -864.8519897460938\n",
      "Iter = 6840 and loss = -864.8521118164062\n",
      "Iter = 6860 and loss = -864.8519287109375\n",
      "Iter = 6880 and loss = -864.8519897460938\n",
      "Iter = 6900 and loss = -864.8519897460938\n",
      "Iter = 6920 and loss = -864.8519897460938\n",
      "Iter = 6940 and loss = -864.8509521484375\n",
      "Iter = 6960 and loss = -864.8499755859375\n",
      "Iter = 6980 and loss = -864.85205078125\n",
      "Iter = 7000 and loss = -864.851806640625\n",
      "Iter = 7020 and loss = -864.8519287109375\n",
      "Iter = 7040 and loss = -864.8519897460938\n",
      "Iter = 7060 and loss = -864.8519897460938\n",
      "Iter = 7080 and loss = -864.8519897460938\n",
      "Iter = 7100 and loss = -864.8502197265625\n",
      "Iter = 7120 and loss = -864.8510131835938\n",
      "Iter = 7140 and loss = -864.8519287109375\n",
      "Iter = 7160 and loss = -864.8519897460938\n",
      "Iter = 7180 and loss = -864.8521118164062\n",
      "Iter = 7200 and loss = -864.85205078125\n",
      "Iter = 7220 and loss = -864.85205078125\n",
      "Iter = 7240 and loss = -864.85205078125\n",
      "Iter = 7260 and loss = -864.8424682617188\n",
      "Iter = 7280 and loss = -864.8519897460938\n",
      "Iter = 7300 and loss = -864.851806640625\n",
      "Iter = 7320 and loss = -864.8519287109375\n",
      "Iter = 7340 and loss = -864.8519897460938\n",
      "Iter = 7360 and loss = -864.8519897460938\n",
      "Iter = 7380 and loss = -864.8519287109375\n",
      "Iter = 7400 and loss = -864.8510131835938\n",
      "Iter = 7420 and loss = -864.849365234375\n",
      "Iter = 7440 and loss = -864.85205078125\n",
      "Iter = 7460 and loss = -864.85205078125\n",
      "Iter = 7480 and loss = -864.8519287109375\n",
      "Iter = 7500 and loss = -864.8519287109375\n",
      "Iter = 7520 and loss = -864.8519287109375\n",
      "Iter = 7540 and loss = -864.846435546875\n",
      "Iter = 7560 and loss = -864.8517456054688\n",
      "Iter = 7580 and loss = -864.8519897460938\n",
      "Iter = 7600 and loss = -864.85205078125\n",
      "Iter = 7620 and loss = -864.8519897460938\n",
      "Iter = 7640 and loss = -864.85205078125\n",
      "Iter = 7660 and loss = -864.8456420898438\n",
      "Iter = 7680 and loss = -864.851318359375\n",
      "Iter = 7700 and loss = -864.851806640625\n",
      "Iter = 7720 and loss = -864.8519897460938\n",
      "Iter = 7740 and loss = -864.85205078125\n",
      "Iter = 7760 and loss = -864.8519287109375\n",
      "Iter = 7780 and loss = -864.85107421875\n",
      "Iter = 7800 and loss = -864.8517456054688\n",
      "Iter = 7820 and loss = -864.8519287109375\n",
      "Iter = 7840 and loss = -864.85205078125\n",
      "Iter = 7860 and loss = -864.8519287109375\n",
      "Iter = 7880 and loss = -864.8519897460938\n",
      "Iter = 7900 and loss = -864.8519287109375\n",
      "Iter = 7920 and loss = -864.8519287109375\n",
      "Iter = 7940 and loss = -864.8515014648438\n",
      "Iter = 7960 and loss = -864.8519287109375\n",
      "Iter = 7980 and loss = -864.8519287109375\n",
      "Iter = 8000 and loss = -864.8519287109375\n",
      "Iter = 8020 and loss = -864.8519287109375\n",
      "Iter = 8040 and loss = -864.8519897460938\n",
      "Iter = 8060 and loss = -864.8519897460938\n",
      "Iter = 8080 and loss = -864.8394165039062\n",
      "Iter = 8100 and loss = -864.8519287109375\n",
      "Iter = 8120 and loss = -864.8518676757812\n",
      "Iter = 8140 and loss = -864.8519287109375\n",
      "Iter = 8160 and loss = -864.8519287109375\n",
      "Iter = 8180 and loss = -864.85205078125\n",
      "Iter = 8200 and loss = -864.85205078125\n",
      "Iter = 8220 and loss = -864.85205078125\n",
      "Iter = 8240 and loss = -864.8519897460938\n",
      "Iter = 8260 and loss = -864.8519287109375\n",
      "Iter = 8280 and loss = -864.8465576171875\n",
      "Iter = 8300 and loss = -864.8499755859375\n",
      "Iter = 8320 and loss = -864.8519287109375\n",
      "Iter = 8340 and loss = -864.8519897460938\n",
      "Iter = 8360 and loss = -864.85205078125\n",
      "Iter = 8380 and loss = -864.8519897460938\n",
      "Iter = 8400 and loss = -864.8519287109375\n",
      "Iter = 8420 and loss = -864.8519287109375\n",
      "Iter = 8440 and loss = -864.8518676757812\n",
      "Iter = 8460 and loss = -864.8519287109375\n",
      "Iter = 8480 and loss = -864.8490600585938\n",
      "Iter = 8500 and loss = -864.8513793945312\n",
      "Iter = 8520 and loss = -864.8518676757812\n",
      "Iter = 8540 and loss = -864.8518676757812\n",
      "Iter = 8560 and loss = -864.8519287109375\n",
      "Iter = 8580 and loss = -864.8519897460938\n",
      "Iter = 8600 and loss = -864.85205078125\n",
      "Iter = 8620 and loss = -864.85205078125\n",
      "Iter = 8640 and loss = -864.8521118164062\n",
      "Iter = 8660 and loss = -864.8521118164062\n",
      "Iter = 8680 and loss = -864.8519287109375\n",
      "Iter = 8700 and loss = -864.8299560546875\n",
      "Iter = 8720 and loss = -864.8478393554688\n",
      "Iter = 8740 and loss = -864.8519287109375\n",
      "Iter = 8760 and loss = -864.8519897460938\n",
      "Iter = 8780 and loss = -864.8519287109375\n",
      "Iter = 8800 and loss = -864.8519287109375\n",
      "Iter = 8820 and loss = -864.8519897460938\n",
      "Iter = 8840 and loss = -864.8518676757812\n",
      "Iter = 8860 and loss = -864.85205078125\n",
      "Iter = 8880 and loss = -864.8519897460938\n",
      "Iter = 8900 and loss = -864.85205078125\n",
      "Iter = 8920 and loss = -864.8519287109375\n",
      "Iter = 8940 and loss = -864.8519287109375\n",
      "Iter = 8960 and loss = -864.8519287109375\n",
      "Iter = 8980 and loss = -864.8519287109375\n",
      "Iter = 9000 and loss = -864.85205078125\n",
      "Iter = 9020 and loss = -864.8519287109375\n",
      "Iter = 9040 and loss = -864.8519287109375\n",
      "Iter = 9060 and loss = -864.8521118164062\n",
      "Iter = 9080 and loss = -864.8519287109375\n",
      "Iter = 9100 and loss = -864.8519287109375\n",
      "Iter = 9120 and loss = -864.85205078125\n",
      "Iter = 9140 and loss = -864.8521118164062\n",
      "Iter = 9160 and loss = -864.8518676757812\n",
      "Iter = 9180 and loss = -864.8514404296875\n",
      "Iter = 9200 and loss = -864.84423828125\n",
      "Iter = 9220 and loss = -864.8507690429688\n",
      "Iter = 9240 and loss = -864.8519897460938\n",
      "Iter = 9260 and loss = -864.8519287109375\n",
      "Iter = 9280 and loss = -864.8519897460938\n",
      "Iter = 9300 and loss = -864.85205078125\n",
      "Iter = 9320 and loss = -864.8519897460938\n",
      "Iter = 9340 and loss = -864.8519287109375\n",
      "Iter = 9360 and loss = -864.85205078125\n",
      "Iter = 9380 and loss = -864.85205078125\n",
      "Iter = 9400 and loss = -864.8519897460938\n",
      "Iter = 9420 and loss = -864.8519897460938\n",
      "Iter = 9440 and loss = -864.8519287109375\n",
      "Iter = 9460 and loss = -864.8519897460938\n",
      "Iter = 9480 and loss = -864.8521118164062\n",
      "Iter = 9500 and loss = -864.85205078125\n",
      "Iter = 9520 and loss = -864.8519897460938\n",
      "Iter = 9540 and loss = -864.85205078125\n",
      "Iter = 9560 and loss = -864.85205078125\n",
      "Iter = 9580 and loss = -864.8519897460938\n",
      "Iter = 9600 and loss = -864.85205078125\n",
      "Iter = 9620 and loss = -864.8519897460938\n",
      "Iter = 9640 and loss = -864.8465576171875\n",
      "Iter = 9660 and loss = -864.8511962890625\n",
      "Iter = 9680 and loss = -864.8517456054688\n",
      "Iter = 9700 and loss = -864.85205078125\n",
      "Iter = 9720 and loss = -864.85205078125\n",
      "Iter = 9740 and loss = -864.8519897460938\n",
      "Iter = 9760 and loss = -864.85205078125\n",
      "Iter = 9780 and loss = -864.8410034179688\n",
      "Iter = 9800 and loss = -864.8517456054688\n",
      "Iter = 9820 and loss = -864.851806640625\n",
      "Iter = 9840 and loss = -864.8519287109375\n",
      "Iter = 9860 and loss = -864.8519287109375\n",
      "Iter = 9880 and loss = -864.8518676757812\n",
      "Iter = 9900 and loss = -864.85205078125\n",
      "Iter = 9920 and loss = -864.8516845703125\n",
      "Iter = 9940 and loss = -864.8510131835938\n",
      "Iter = 9960 and loss = -864.8514404296875\n",
      "Iter = 9980 and loss = -864.8519287109375\n"
     ]
    }
   ],
   "source": [
    "n_iter = 10000\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(f.parameters(), learning_rate)\n",
    "\n",
    "x, thetas = D[:,0], D[:,1]\n",
    "for i in range(n_iter):\n",
    "    \n",
    "    loss_train = f.loss(thetas,x)\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i%20==0:\n",
    "        print(f\"Iter = {i} and loss = {loss_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = torch.distributions.Normal(torch.Tensor([0]), torch.Tensor([1])).sample((1000, ))\n",
    "\n",
    "z_prime = f.forward(Z, x)\n",
    "\n",
    "#sns.kdeplot(data= z_prime.detach().squeeze())\n",
    "\n",
    "#for xi in x:\n",
    "#    plt.axvline(xi, color='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4030084.062499998"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = (   mu0/(sigma0**2)  ) * ( 1/sigma0**2 + 1/sigma**2  )**(-1)\n",
    "\n",
    "B = ( 1/sigma**2 ) * (1/sigma**2 + 1/sigma0**2 )**(-1)\n",
    "\n",
    "A = ( 1/sigma0**2 + 1/sigma**2)\n",
    "borne = mu0**2 + (1 + (sigma0**2)/(sigma**2) ) * (A**2)\n",
    "borne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C = 0.007481296758104739 and gamma = 0.012515312992036343\n",
      "B = 0.9975062344139651 ansd beta = 0.9961519241333008\n",
      " Â = 4030084.062499998 and alpha^2 = 0.010383064157700128\n"
     ]
    }
   ],
   "source": [
    "print(f\" C = {C} and gamma = {f.gamma.item()}\")\n",
    "print(f\"B = {B} ansd beta = {f.beta.item()}\")\n",
    "print(f\" Â = {borne} and alpha^2 = {torch.exp(f.omega).item()**2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: Vérifier si juste, comparer avec code de zuko"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
